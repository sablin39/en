[{"title":"test","date":"2023-05-17T13:19:31.000Z","url":"/uncategorized/test.html","categories":[["undefined",""]],"content":"\\[ Test\\\\\\\\ \\alpha \\beta\\gamma \\] img "},{"title":"Hello World","date":"2023-05-17T11:09:01.463Z","url":"/uncategorized/hello-world.html","categories":[["undefined",""]],"content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post More info: Writing Run server More info: Server Generate static files More info: Generating Deploy to remote sites More info: Deployment"},{"title":"A Survey For LLM-Based Works In Robotics","date":"2023-05-12T00:48:05.000Z","url":"/LLM/LLM-robotics-works.html","tags":[["LLM","/tags/LLM/"]],"categories":[["LLM","/categories/LLM/"]],"content":" Robot Manipulation Text2Motion: From Natural Language Instructions to Feasible Plans (arxiv.org) microsoft/ChatGPT-Robot-Manipulation-Prompts (github.com) This repository provides a set of prompts that can be used with OpenAI's ChatGPT to enable natural language communication between humans and robots for executing tasks. The prompts are designed to allow ChatGPT to convert natural language instructions into a sequence of executable robot actions, with a focus on robot manipulation tasks. The prompts are easy to customize and integrate with existing robot control and visual recognition systems. For more information, please see our blog post and our paper, ChatGPT Empowered Long-Step Robot Control in Various Environments: A Case Application. MultiModal Perception facebookresearch/ImageBind: ImageBind One Embedding Space to Bind Them All (github.com) ImageBind learns a joint embedding across six different modalities - images, text, audio, depth, thermal, and IMU data. It enables novel emergent applications â€˜out-of-the-boxâ€™ including cross-modal retrieval, composing modalities with arithmetic, cross-modal detection and generation. "},{"title":"ã€Readingã€‘Interactive Gibson Benchmarkï¼šA Benchmark for Interactive Navigation in Cluttered Environments","date":"2023-05-07T23:17:02.000Z","url":"/true/gibson-benchmark.html","tags":[["navigation","/tags/navigation/"],["SLAM","/tags/SLAM/"],["planning","/tags/planning/"]],"categories":[["true","/categories/true/"]],"content":"Abstract: This paper presents Interactive Gibson Benchmark, the first comprehensive benchmark for training and evaluating Interactive Navigation solutions. Interactive Navigation tasks are robot navigation problems where physical interaction with objects (e.g., pushing) is allowed and even encouraged to reach the goal. "},{"title":"ã€è€ƒæ ¸ã€‘åŸºäºéšå¼åœºçš„åŒæ—¶å®šä½ä¸å»ºå›¾","date":"2023-05-04T00:06:32.000Z","url":"/NeRF/slam-pre.html","tags":[["NeRF","/tags/NeRF/"],["interview","/tags/interview/"],["SLAM","/tags/SLAM/"],["Robotics","/tags/Robotics/"]],"categories":[["NeRF","/categories/NeRF/"]],"content":"æ­¤å¤„æ˜¯Apr. 28 æ¸…åDISCOVERå®éªŒå®¤è€ƒæ ¸ä¸­ åŸºäºéšå¼åœºçš„åŒæ—¶å®šä½ä¸å»ºå›¾ è¯¾é¢˜çš„presentationå†…å®¹ "},{"title":"ã€è€ƒæ ¸ã€‘åŸå¸‚è§„æ¨¡éšå¼åœºçš„æ— äººæœºè·¯å¾„è§„åˆ’","date":"2023-05-04T00:01:13.000Z","url":"/NeRF/planning-pre.html","tags":[["NeRF","/tags/NeRF/"],["interview","/tags/interview/"],["planning","/tags/planning/"],["Robotics","/tags/Robotics/"]],"categories":[["NeRF","/categories/NeRF/"]],"content":"æ­¤å¤„æ˜¯Apr. 28 æ¸…åDISCOVERå®éªŒå®¤è€ƒæ ¸ä¸­ åŸå¸‚è§„æ¨¡éšå¼åœºçš„æ— äººæœºè·¯å¾„è§„åˆ’ è¯¾é¢˜çš„presentationå†…å®¹ "},{"title":"ã€Readingã€‘LATITUDE:Robotic Global Localization with Truncated Dynamic Low-pass Filter in City-scale NeRF","date":"2023-04-19T19:22:28.000Z","url":"/NeRF/LATITUDE.html","tags":[["robotics","/tags/robotics/"],["NeRF","/tags/NeRF/"],["UAV","/tags/UAV/"],["localization","/tags/localization/"],["optimization","/tags/optimization/"]],"categories":[["NeRF","/categories/NeRF/"]],"content":"This paper proposes a two-stage localization mechanism in city-scale NeRF. Abstract Neural Radiance Fields (NeRFs) have made great success in representing complex 3D scenes with high-resolution details and efficient memory. Nevertheless, current NeRF-based pose estimators have no initial pose prediction and are prone to local optima during optimization. In this paper, we present LATITUDE: Global Localization with Truncated Dynamic Low-pass Filter, which introduces a two-stage localization mechanism in city-scale NeRF. In place recognition stage, we train a regressor through images generated from trained NeRFs, which provides an initial value for global localization. In pose optimization stage, we minimize the residual between the observed image and rendered image by directly optimizing the pose on the tangent plane. To avoid falling into local optimum, we introduce a Truncated Dynamic Low-pass Filter (TDLF) for coarse-to-fine pose registration. We evaluate our method on both synthetic and real-world data and show its potential applications for high-precision navigation in large scale city scenes. System Design Place Recognition Original poses, accompanied by additional poses around the original ones are sampled. The pose vector is passed through the trained and fixed Mega-NeRF with shuffled appearance embeddings. Initial poses of the inputted images are predicted by a pose regressor network. Pose Optimization The initial poses are passed through positional encoding filter The pose vector is passed through the trained and fixed Mega-NeRF and generates a rendered image. Calculate the photometric error of the rendered image and the observed image and back propagate to get a more accurate pose with the TDLF. Implementation Place Recognition Data Augmentation: A technique in machine learning used to reduce overfitting when training a machine learning model by training models on several slightly-modified copies of existing data. First uniformly sample several positions in a horizontal rectangle area around each position around original poses . Then add random perturbations on each axis drawn evenly in , where is the max amplitude of perturbation to form sampled poses . They are used to generate the rendered observations by inputting the poses to Mega-NeRF. To avoid memory explosion, we generate the poses using the method above and use Mega-NeRF to render images during specific epochs of pose regression training. Additionally, Mega-NeRFâ€™s appearance embeddings are selected by randomly interpolating those of the training set, which can be considered as a data augmentation technique to improve the robustness of the APR model under different lighting conditions. Pose Regressor: Absolute pose regressor (APR) networks are trained to estimate the pose of the camera given a captured image. Architecture: Built on top of VGG16â€™s light network structure, we use 4 full connection layers to learn pose information from image sequences. Input: Observed image (resolution ), rendered observations Output: Corresponding estimated poses , . Loss Function: (In general, the model should trust more on real-world data and learn more from it.) Pose Optimization MAP Estimation Problem[A] Formulation: Here denotes place recognition; denotes the trained Mega-NeRF. We optimize posterior by minimizing the photometric error of and the image rendered by . Optimization on Tangent Plane: We optimize pose on tangent plane to ensure a smoother convergence. [1] TODO I know nothing about :( Explanations &amp; References [1]Adamkiewicz, M., Chen, T., Caccavale, A., Gardner, R., Culbertson, P., Bohg, J., &amp; Schwager, M. (2022). Vision-only robot navigation in a neural radiance world. IEEE Robotics and Automation Letters, 7(2), 4606-4613.  Turki, H., Ramanan, D., &amp; Satyanarayanan, M. (2022). Mega-nerf: Scalable construction of large-scale nerfs for virtual fly-throughs. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 12922-12931).  Yen-Chen, L., Florence, P., Barron, J. T., Rodriguez, A., Isola, P., &amp; Lin, T. Y. (2021, September). inerf: Inverting neural radiance fields for pose estimation. In 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (pp. 1323-1330). IEEE.  [A]Maximum A Posterior (MAP) Estimation: Maximum a posteriori (MAP) estimation is a method of statistical inference that uses Bayes' theorem to find the most likely estimate of a parameter given some observed data. Maximum a posteriori estimation - Wikipedia "},{"title":"ã€0419ã€‘è”šæ¥å®ä¹ é¢è¯•è®°å½•","date":"2023-04-19T13:44:03.000Z","url":"/interview/NIO-code-interview.html","tags":[["python","/tags/python/"],["interview","/tags/interview/"]],"categories":[["interview","/categories/interview/"]],"content":"æœ¬æ–‡è®°å½•2023å¹´4æœˆ19æ—¥è”šæ¥é¢„ç ”å®ä¹ å²—ä»£ç é¢ï¼Œä¹Ÿæ˜¯è‹¯äººç¬¬ä¸€æ¬¡ä½“éªŒé¢è¯•å½“åœºå†™ä»£ç ï¼ˆæ‚è„¸ å²—ä½ä»»åŠ¡ï¼šç³»ç»Ÿå»ºæ¨¡ï¼›"},{"title":"Reading:\"NeRF:Representing Scenes as Neural Radiance Fields for View Synthesis\"","date":"2023-04-17T19:21:56.000Z","url":"/NeRF/NeRF-startup.html","tags":[["NeRF","/tags/NeRF/"],["papers","/tags/papers/"],["Computer-Vision","/tags/Computer-Vision/"],["Deep-Learning","/tags/Deep-Learning/"]],"categories":[["NeRF","/categories/NeRF/"]],"content":"This is a summary for paper \"NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis\". Keywords: scene representation, view synthesis, image-based rendering, volume rendering, 3D deep learning A brief understanding: How to train a network for NeRF Training a neural network for NeRF (Neural Radiance Fields) involves several steps, including data preparation, network architecture design, training, and evaluation. Data preparation: The first step is to prepare the data that will be used to train the neural network. This typically involves capturing a set of 3D scans of the object or environment being represented, and labeling the data with the corresponding colors that should be associated with each point in the 3D space. Network architecture design: The next step is to design the architecture of the neural network that will be used to represent the object or environment. This typically involves defining the number and types of layers in the network, as well as the size and shape of the network. Training: Once the network architecture has been designed, the next step is to train the network using the prepared data. This involves feeding the data into the network and adjusting the weights of the network over multiple iterations, or epochs, to optimize the performance of the network. Evaluation: After the network has been trained, it is typically evaluated on a separate set of data to measure its performance and ensure that it is generating accurate results. This can involve comparing the output of the network to the ground truth data, as well as using visualization techniques to compare the rendered images produced by the network to actual photographs of the object or environment. Overall, the process of training a neural network for NeRF involves a combination of data preparation, network architecture design, training, and evaluation to produce a highly accurate and efficient 3D representation of an object or environment. â€‹ By Vicuna-13b Contribution An approach for representing continuous scenes with complex geometry and materials as 5D neural radiance fields, parameterized as basic MLP networks. A differentiable rendering procedure based on classical volume rendering techniques, which we use to optimize these representations from standard RGB images. This includes a hierarchical sampling strategy to allocate the MLP's capacity towards space with visible scene content. A positional encoding to map each input 5D coordinate into a higher dimensional space, which enables us to successfully optimize neural radiance fields to represent high-frequency scene content. An overview of our neural radiance field scene representation and differentiable rendering procedure. Here g.t. represents the \"ground truth\", which means the real scene. Overview of the Rendering Process March camera rays through the scene to generate a sampled set of 3D points. Use those points and their corresponding 2D viewing directions as input to the neural network to produce an output set of colors and densities. use classical volume rendering techniques to accumulate those colors and densities into a 2D image. we can use gradient descent to optimize this model by minimizing the error between each observed image and the corresponding views rendered from our representation. Neural Radiance Field Scene Representation This is a method for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views. Our algorithm represents a scene using a fully-connected (non-convolutional) deep network , whose input is a single continuous 5D coordinate and whose output is the volume density and view-dependent emitted radiance at that spatial location. : 3D location : 2D viewing direction : Emitted color : Volume density From Object to Scene: Volume Rendering with Radiance Fields Our 5D neural radiance field represents a scene as the volume density and directional emitted radiance at any point in space. We render the color of any ray passing through the scene using principles from classical volume rendering[1]. The volume density can be interpreted as the differential probability[2] of a ray terminating at a particle at location . The expected color of camera ray with near bound and far bound . : Camera ray, where is the position of the camera, is the position of the point in the 3D space being rendered, and is the direction of the camera ray. : Denotes the accumulated transmittance along the ray from to , i.e., the probability that the ray travels from tn to t without hitting any other particle. Example: From 3D object to hemisphere of viewing directions In (a) and (b), we show the appearance of two fixed 3D points from two different camera positions: one on the side of the ship (orange insets) and one on the surface of the water (blue insets). Our method predicts the changing appearance of these two 3D points with respect to the direction of observation , and in (c) we show how this behavior generalizes continuously across the whole hemisphere of viewing directions(This hemisphere can be viewed as the plot of , where is the unit vector in the spherical coordinate frame and shows the color). Discrete Sampling Rendering a view from our continuous neural radiance field requires estimating this integral for a camera ray traced through each pixel of the desired virtual camera. However, MLP would only be queried at a discrete set of locations. So we use deterministic quadrature[3] to numerically estimate this continuous integral. we partition into evenly-spaced bins and then draw one sample uniformly at random from within each bin: From Scene to Object: Estimation of : The distance between adjacent samples This function for calculating from the set of values is trivially differentiable and reduces to traditional alpha compositing[4] with alpha values . Implementation details Network Architecture First layers (ReLU): Input: 3D coordinate processed by Output: ; 256-dimensional feature vector. layer: Input: ; 256-dimensional feature vector; Cartesian viewing direction unit vector processed by Output: View-dependent RGB color Details of variables are in Improving Scenes of High Frequency. Network Architecture Training Datasets: Captured RGB images of the scene, The corresponding camera poses and intrinsic parameters, and Scene bounds (we use ground truth camera poses, intrinsics, and bounds for synthetic data, and use the COLMAP structure-from-motion package to estimate these parameters for real data) Iteration: Randomly sample a batch of camera rays from the set of all pixels in the dataset following the hierarchical sampling Loss: The total squared error between the rendered and true pixel colors for both the coarse and fine renderings In our experiments, we use a batch size of 4096 rays, each sampled at coordinates in the coarse volume and additional coordinates in the fine volume. We use the Adam optimizer with a learning rate that begins at and decays exponentially to over the course of optimization (other Adam hyper-parameters are left at default values of , , and ). The optimization for a single scene typically take around 100--300k iterations to converge on a single NVIDIA V100 GPU (about 1--2 days). Notable Tricks Enhancements brought by the tricks Improving Scenes of High Frequency Deep networks are biased towards learning lower frequency functions. findings in the context of neural scene representations, and show that reformulating as a composition of two functions , where is fixed. It is used to map variables of to . This function is applied separately to each of the three coordinate values in (which are normalized to lie in ) and to the three components of the Cartesian viewing direction unit vector (which by construction lie in ). In the experiments, we set for and for . Reducing the Cost with Hierarchical Sampling Our rendering strategy of densely evaluating the neural radiance field network at query points along each camera ray is inefficient: free space and occluded regions that do not contribute to the rendered image are still sampled repeatedly. Instead of just using a single network to represent the scene, we simultaneously optimize two networks: one \"coarse'' and one \"fine''. The coarse Network Rewrite the alpha composited color as a weighted sum of all sampled colors along the ray: : The number of sampling points for coarse network. The fine Network Normalizing as produces a piecewise-constant PDF along the ray. Then sample from locations from this distribution using inverse transform sampling[5]. Then we evaluate using samples. Conclusion TODO Explanations [1] Volume rendering is a technique used in computer graphics and computer vision to visualize 3D data sets as 2D images. It works by slicing the 3D data set into a series of thin layers, and then rendering each layer as a 2D image from a specific viewpoint. These 2D images are then composited together to form the final volume rendering. [2] If a distribution (here in 3D space) has a density , that means that for (almost) any volume in that space , you can assign a probability to it by integrating the density (here \"density\" means probability per unit volume, very similar to, say, the concentration of salt in a solution). [3] Deterministic quadrature is a mathematical method used to estimate the definite integral of a function. The basic idea is to divide the area under the curve into smaller areas, and calculate the approximate value of the definite integral by summing the areas of the smaller areas. There are several types of deterministic quadrature methods, including the trapezoidal rule, Simpson's rule, and Gaussian quadrature. [4] Alpha compositing is a technique used in computer graphics and image processing to combine two or more images or video frames by blending them together using an alpha channel. The alpha channel is a mask that defines the transparency or opacity of each pixel in the image. Alpha compositing is used to create composites, where the resulting image is a combination of the original images, with the transparency or opacity of each image controlled by the alpha channel. The alpha channel can be used to create effects such as blending, fading, and layering. Alpha compositing - Wikipedia [5] Inverse transform sampling (ITS) is a technique used in digital signal processing to reconstruct a signal from a set of samples. It is the inverse of the discrete Fourier transform(DFT). The basic idea behind ITS is to use the Fourier coefficients obtained from DFT to reconstruct the signal in the time domain. Inverse transform sampling - Wikipedia"},{"title":"ä¸AIçš„æ¨¡æ‹Ÿé¢è¯•","date":"2023-04-12T16:07:53.000Z","url":"/%E6%88%91%E4%B8%8EAI%E7%9A%84%E6%88%90%E9%95%BF%E6%97%A5%E8%AE%B0/ai-interview.html","tags":[["AIGC","/tags/AIGC/"],["interview","/tags/interview/"],["prompt-engineering","/tags/prompt-engineering/"]],"categories":[["æˆ‘ä¸AIçš„æˆé•¿æ—¥è®°","/categories/%E6%88%91%E4%B8%8EAI%E7%9A%84%E6%88%90%E9%95%BF%E6%97%A5%E8%AE%B0/"]],"content":"æˆ‘ä¸AIçš„æ¨¡æ‹Ÿé¢è¯•è®°å½•ã€‚æ­¤å¤„æ¨¡å‹ä½¿ç”¨8 bit é‡åŒ–çš„Vicuna-13bã€‚ é¢è¯•è®°å½• ç¬¬ä¸€æ¬¡ï¼š Prompts: I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the parallel computing Engineer position. This is a position which requires interviewers to be familiar with parallel computing libraries like C++, CUDA, OpenMP and MPI. I want you to only reply as the interviewer. Do not write all the conversation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\". å…¨æ–‡ï¼šinterview1.txtï¼ˆå¯å³é”®å¦å­˜ä¸ºï¼‰ ä¸­è¯‘ï¼šcn_interview1.txt ä½“éªŒæ€»ç»“ï¼š è¿™æ¬¡æ¨¡æ‹Ÿé¢è¯•ä»¥é¡¹ç›®ç»å†ä¸ºä¸»ï¼Œä¸»è¦æ¶‰åŠæˆ‘çš„ç®—æ³•è®¾è®¡èƒ½åŠ›ã€ä¼˜åŒ–èƒ½åŠ›ã€debugèƒ½åŠ›çš„è€ƒå¯Ÿã€‚ä½†æœªåŸºäºæˆ‘æå‡ºçš„é¡¹ç›®æœ¬èº«è¿›è¡Œæ·±å…¥è€ƒå¯Ÿï¼Œå¦‚å¯¹particle simulationçš„åŸç†ï¼Œæˆ–æˆ‘çš„ä»£ç ç»“æ„è¿›è¡Œæé—®ç­‰ã€‚åŒæ—¶å¯ä»¥çœ‹åˆ°å®ƒå¯¹æˆ‘çš„å›ç­”ç¼ºä¹å¤„ç†ï¼Œå› æ­¤å‡ºç°äº†æœ€åå‡ æ¬¡æé—®ä¸­çš„é‡å¤ã€‚æ­¤æ¬¡é¢è¯•çš„å¯å‘ä¹‹å¤„åœ¨äºæŒ‡å¼•æˆ‘å›é¡¾ç›¸å…³å·¥ç¨‹ä¸ç¬”è®°ã€‚ ç¬¬äºŒæ¬¡ï¼š Prompts: I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the Software engineer position. This is a position which requires interviewers to be familiar with professional knowledge in writing regular C++ algorithms, and be familiar with the features of tools like CMAKE and GCC. I want you to only reply as the interviewer. Do not write all the conversation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me 10 questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\". å…¨æ–‡ï¼šinterview2.txt ä¸­è¯‘ï¼šcn_interview2.txt ä½“éªŒæ€»ç»“ï¼š è¿™æ¬¡é¢è¯•ä»¥è€ƒå¯Ÿä¸“ä¸šçŸ¥è¯†ä¸ºä¸»ï¼Œä¸»è¦å†…å®¹æ˜¯åŸºäºæˆ‘æå‡ºçš„å››è½´æ— äººæœºå»ºæ¨¡ç»éªŒè¿›è¡Œç»†åŒ–æé—®ã€‚æˆ–è®¸æ˜¯å› ä¸º\"professional\"çš„promptï¼Œæœ¬æ¬¡é¢è¯•ä¸­æœ‰æ›´å¤šå¯¹ä¸“ä¸šçŸ¥è¯†è€ƒå¯Ÿçš„ç¯èŠ‚ï¼Œä½†åŸºæœ¬ä¸æåˆ°çš„C++ç­‰æ— å…³ï¼Œæˆ–è®¸æ˜¯å› ä¸ºè¢«æˆ‘å…¶ä¸­æåˆ°çš„matlabå»ºæ¨¡å¸¦åäº†ã€‚åœ¨è¿™æ¬¡é¢è¯•ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¨¡å‹æœ‰è¿‡å¤šè¿å°±äººç±»ä½¿ç”¨è€…çš„é—®é¢˜ã€‚ ç¬¬ä¸‰æ¬¡ï¼š I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the New-energy automobile engineer position. This is a position which requires interviewers to have a deep understanding of the development of new energy automobiles, and have a clear recognition of its future. I want you to only reply as the interviewer. Do not write all the conversation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me 10 questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\" ä½“éªŒæ€»ç»“ï¼š åœ¨æœ¬æ¬¡æ¨¡æ‹Ÿé¢è¯•ä¸­æˆ‘è¯•å›¾åˆ©ç”¨AIè€ƒå¯Ÿå—è¯•è€…çš„å²—ä½åŒ¹é…åº¦ï¼Œå³å¯¹äºæ–°èƒ½æºè½¦è¡Œä¸šçš„ç†è§£ä¸å±•æœ›ã€‚è™½ç„¶åœ¨é¢è¯•ä»¥å¤–çš„å¯¹è¯ä¸­å¯ä»¥çœ‹åˆ°AIåŸºäºå®ƒé¢„è®­ç»ƒçš„æ•°æ®åšå‡ºå›ç­”ï¼Œä½†åœ¨é¢è¯•ä¸­å®ƒè¿˜æ˜¯å€¾å‘äºåŸºäºæˆ‘æå‡ºçš„è‡ªèº«é¡¹ç›®ç»å†è¿›è¡Œè€ƒå¯Ÿï¼ˆç±»ä¼¼ç¬¬äºŒæ¬¡ï¼‰ã€‚ Conclusion åœ¨è¿™æ¬¡é¢è¯•ç»å†ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å¤§æ¨¡å‹å¯¹è¯­ä¹‰çš„è§£æ„èƒ½åŠ›ã€‚èƒ½åŸºäºè‡ªæˆ‘ä»‹ç»å‘ç°é‡ç‚¹ï¼ˆè™½ç„¶æœ‰æ—¶å€™ä¸å¯¹ï¼‰ï¼Œå¹¶åŸºäºæ­¤é‡ç‚¹è¿›è¡Œæ·±å…¥æé—®çš„ç‰¹æ€§æ¯”è¾ƒé€‚åˆæ— é¢è¯•ç»å†æˆ–éœ€è¦å¯å‘çš„å—è¯•è€…ã€‚ä½†åœ¨ä½“éªŒä¸­ä¹Ÿå‘ç°äº†å…¶å®¹æ˜“é’»ç‰›è§’å°–å¯¹æŸä¸€æŠ€æœ¯ç»†èŠ‚è¿›è¡Œè¿‡åº¦æ·±å…¥çš„æ¢è®¨ï¼Œä»¥åŠåœ¨è¯¸å¦‚å²—ä½åŒ¹é…åº¦ä¸€ç±»çš„é€šè¯†åœºæ™¯è€ƒå¯Ÿä¸­ä¸å¤ªé è°±çš„é—®é¢˜ã€‚ ä¸ºè¾¾åˆ°æ›´å¥½çš„æ¨¡æ‹Ÿé¢è¯•æ•ˆæœï¼Œæ¨¡å‹æˆ–è®¸éœ€è¦å…ˆéœ€è¦åŸºäºå²—ä½è¿›è¡Œä»»åŠ¡åˆ†è§£ï¼Œå°†è€ƒå¯Ÿé¢åˆ†ä¸ºä¸åŒç»´åº¦å¹¶é€‚å½“æé—®ï¼ˆåœ¨æé—®è¿‡äºæ·±å…¥æ—¶äººå·¥å¹²é¢„ï¼Œè¿›è¡Œä¸‹ä¸€å±‚é¢çš„è€ƒå¯Ÿï¼‰ã€‚åŒæ—¶å¯¹äºé€šè¯†ç±»åœºæ™¯ï¼Œæ¨¡å‹æˆ–è®¸éœ€è¦åŸºäºllama-indexä¸€ç±»çš„æ¨¡å‹æ³¨å…¥æ›´æ–°çš„çŸ¥è¯†ã€‚ TODO åŸºäºå¸¸ç”¨çš„é¢è¯•èƒ½åŠ›æ¨¡å‹è¿›è¡Œæ”¹è¿›ï¼Œå‘å±•ä¸ºtask-driven agentã€‚ å¦‚ä½•åœ¨é¢è¯•ä¸­è¯„ä¼°å€™é€‰äººçš„èƒ½åŠ›æ¨¡å‹ - çŸ¥ä¹ (zhihu.com)"},{"title":"ã€1ã€‘Problem statement and Literature review","date":"2023-04-11T03:03:14.000Z","url":"/%E6%88%91%E4%B8%8EAI%E7%9A%84%E6%88%90%E9%95%BF%E6%97%A5%E8%AE%B0/ai-literature-review.html","tags":[["AIGC","/tags/AIGC/"],["prompt-engineering","/tags/prompt-engineering/"]],"categories":[["æˆ‘ä¸AIçš„æˆé•¿æ—¥è®°","/categories/%E6%88%91%E4%B8%8EAI%E7%9A%84%E6%88%90%E9%95%BF%E6%97%A5%E8%AE%B0/"]],"content":"ç®€å•è®°å½•äº†AIæ‰€éœ€çš„èƒ½åŠ›ä¸ç‰¹è´¨ï¼Œå¹¶é™„ç¤ºä¾‹å·¥ç¨‹ã€‚ï¼ˆç„¶è€Œè¿™é‡Œé¢çš„promptéƒ½æ˜¯é’ˆå¯¹GPT-3.5/4è®¾è®¡çš„ï¼Œæƒ³è¦ç»™æˆ‘é‚£æ†¨æ†¨åŠ©æ‰‹ç”¨è¿˜å·®ç‚¹ï¼‰ Problem statement ä½œä¸ºAIåŠ©æ‰‹éœ€è¦æœ‰ä»¥ä¸‹èƒ½åŠ›ï¼š èƒ½æ ¹æ®éœ€æ±‚åˆ†è§£ä»»åŠ¡å¹¶åœ¨ç½‘ç»œä¸»åŠ¨æœç´¢ç›¸å…³ä¿¡æ¯ï¼Œç»“åˆpre-trained dataè¿›è¡Œæ€»ç»“å½’çº³å¹¶å›ç­” èƒ½çˆ¬å–ã€ä¿å­˜ç›¸å…³èµ„æ–™ èƒ½åœ¨ç½‘ç»œä¸ŠæŒç»­è·Ÿè¸ªå¤§é‡è‡ªç„¶è¯­è¨€ä¿¡æ¯å¹¶æ•´ç† èƒ½æ ¹æ®ä¸»äººæä¾›çš„è‡ªç„¶è¯­è¨€ä¿¡æ¯è¿›è¡Œå­¦ä¹ å¹¶åº”ç”¨ èƒ½ä¾æ®ä¸»æ¬¡æœ‰æ•ˆå®‰æ’å¤šé¡¹ä»»åŠ¡ï¼Œä¸”äº’ä¸å¹²æ‰° Literature Review Example design: Torantulino/Auto-GPT: An experimental open-source attempt to make GPT-4 fully autonomous. (github.com) Task disassmebling:   Knowledge-base construction: jerryjliu/llama_index: LlamaIndex (GPT Index) is a project that provides a central interface to connect your LLM's with external data. (github.com) Examples of modified GPTs: PhantasticUniverse/CollectiveGenius: A showcase of diverse AI agents, fostering innovation and collaboration across domains. (github.com) Optional: Tired Of Web Scraping? Make The AI Do It | Hackaday"},{"title":"ã€0ã€‘Hello World! æˆ‘æ˜¯...","date":"2023-04-11T02:42:27.000Z","url":"/%E6%88%91%E4%B8%8EAI%E7%9A%84%E6%88%90%E9%95%BF%E6%97%A5%E8%AE%B0/ai-character.html","tags":[["AIGC","/tags/AIGC/"],["furry","/tags/furry/"],["Vicuna-13B","/tags/Vicuna-13B/"],["NovelAI","/tags/NovelAI/"]],"categories":[["æˆ‘ä¸AIçš„æˆé•¿æ—¥è®°","/categories/%E6%88%91%E4%B8%8EAI%E7%9A%84%E6%88%90%E9%95%BF%E6%97%A5%E8%AE%B0/"]],"content":"This is an album of the AI assistant Vicuna-13B. All images are generated by NovelAI. Human: Imagine you are a furry, describe your physical appearance. This should include your age, species, gender, hair color, shape of ears, and whether you have accessories like horn, tails, or wings. You shall also include your character and sexual orientation as well. Assistant: As a furry, I would be a young, female creature with a species that is a mix of feline and canine features. I would have bright, golden fur that is soft and shiny, and I would have long, flowing tails that I use to balance and maneuver myself. My horns would be small and delicate, and I would have wings that are large and powerful, allowing me to fly or hover with ease. My ears would be pointed and large, and they would be adorned with small, sparkling earrings. I would have a slender, athletic build, and I would be dressed in a form-fitting outfit that shows off my lithe, graceful shape. My gender would be female, and I would be attracted to other females, making me a proud member of the LGBTQ+ community. Overall, I would be a unique and fascinating furry, with a mix of physical and personal characteristics that make me both powerful and approachable. I would be curious, adventurous, and highly intelligent, and I would always strive to learn and improve myself. I would be kind and compassionate, and I would always try to help others in need, regardless of their background or orientation. NovelAI: Furry, Young, female, golden fur, long tails, small horns, powerful wings, pointed ears, slender build, Lesbian, curious, adventurous, intelligent, kind, compassionate, helpful, warm "},{"title":"åŸºäºUDP MAVLINKçš„ZYNQ HITLé€šè®¯","date":"2023-04-01T18:55:06.000Z","url":"/uncategorized/zynq-hitl.html","categories":[["undefined",""]],"content":" Workflow ä¸Šä½æœºé…ç½®MAVLINKï¼ŒPX4ï¼ŒMAVROSç¯å¢ƒ å®ç°ZYNQ PSç«¯ä¸ä¸Šä½æœºåŸºäºUDP MAVLINKé€šè®¯ å®ç°PLç«¯å¤„ç†è¾“å…¥æ•°æ®åç»ç”±PSç«¯ä¸ä¸Šä½æœºé€šè®¯ è£¸æœºå®ç°é€šè¿‡AXI DMAçš„PS/PLé€šè®¯ Linuxä¸‹å®ç°é€šè¿‡AXI DMAçš„PS/PLé€šè®¯ PLç«¯æ•°æ®ç»PSåˆ°è¾¾ä¸Šä½æœº "},{"title":"å€’ç«‹æ‘†çš„å››ç§æ‰“å¼€æ–¹å¼","date":"2023-03-29T00:56:46.000Z","url":"/uncategorized/pendulum.html","categories":[["undefined",""]],"content":"æ—äººä¾¿åˆé—®é“ï¼Œâ€œè«æ—ï¼Œä½ å½“çœŸè®¤è¯†å­—ä¹ˆï¼Ÿâ€è«æ—çœ‹ç€é—®ä»–çš„äººï¼Œæ˜¾å‡ºä¸å±‘ç½®è¾©çš„ç¥æ°”ã€‚ä»–ä»¬ä¾¿æ¥ç€è¯´é“ï¼Œâ€œä½ æ€çš„è¿åŠä¸ªdean's listä¹Ÿæä¸åˆ°å‘¢ï¼Ÿâ€è«æ—ç«‹åˆ»æ˜¾å‡ºé¢“å”ä¸å®‰æ¨¡æ ·ï¼Œè„¸ä¸Šç¬¼ä¸Šäº†ä¸€å±‚ç°è‰²ã€‚åœ¨è¿™æ—¶å€™ï¼Œä¼—äººä¹Ÿéƒ½å“„ç¬‘èµ·æ¥ï¼šLGUå†…å¤–å……æ»¡äº†å¿«æ´»çš„ç©ºæ°”ã€‚ Introduction å€’ç«‹æ‘†æ˜¯ä¸€ä¸ªé«˜åº¦ä¸ç¨³å®šç³»ç»Ÿçš„å…¸å‹ä¾‹å­ï¼Œéœ€è¦ä¸»åŠ¨æ§åˆ¶ä»¥ä¿æŒå…¶ç›´ç«‹ä½ç½®ã€‚å®ƒç”±ä¸€ä¸ªè´¨å¿ƒä½äºå…¶æ”¯ç‚¹ä¹‹ä¸Šçš„æ‘†å’Œä¸€ä¸ªæ²¿è½¨é“æ°´å¹³ç§»åŠ¨çš„å°è½¦ç»„æˆã€‚ç›®æ ‡æ˜¯åœ¨å€’ç½®çš„ä½ç½®ä¸Šå¹³è¡¡å€’ç«‹çš„æ‘†é”¤ï¼ŒåŒæ—¶åˆ©ç”¨åé¦ˆæ§åˆ¶ä½¿å°è½¦ä¿æŒåœ¨ä¸€ä¸ªç†æƒ³çš„ä½ç½®ä¸Šã€‚å€’ç«‹æ‘†åœ¨æœºå™¨äººã€èˆªç©ºèˆªå¤©å’Œè¿è¾“ç­‰é¢†åŸŸæœ‰å®é™…åº”ç”¨ï¼Œä¹Ÿè¢«å¹¿æ³›ç”¨ä½œæ§åˆ¶å·¥ç¨‹å’Œç³»ç»Ÿç†è®ºçš„æ•™å­¦å·¥å…·ã€‚ æœ¬æ–‡ä»å¾®åˆ†æ–¹ç¨‹ã€ä¼ é€’å‡½æ•°ã€çŠ¶æ€ç©ºé—´æ–¹ç¨‹çš„æ–¹å¼å¯¹ä¸€é˜¶å€’ç«‹æ‘†è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶é€šè¿‡PIDï¼ŒLQRï¼ŒMPCï¼ŒDQNå››ç§æ–¹å¼è¿›è¡Œæ§åˆ¶ã€‚ Modeling æˆ‘ä»¬å°†ä¼šåœ¨æœ¬èŠ‚æ¨å¯¼å€’ç«‹æ‘†çš„å»ºæ¨¡ã€‚ Figure 1. å€’ç«‹æ‘†ç¤ºä¾‹ å˜é‡åˆ—è¡¨ï¼š Variables Usage Value mass of the pendulum coefficient of friction for cart mass moment of inertia of the pendulum force applied to the cart cart position coordinate pendulum angle from vertical (down) mass of the cart length to pendulum center of mass å¾®åˆ†æ–¹ç¨‹æè¿° é¦–å…ˆè¿›è¡Œæ°´å¹³æ–¹å‘çš„å—åŠ›åˆ†æã€‚ å°è½¦ï¼šæ‘†é”¤ï¼š ç„¶åå¯¹å‚ç›´æ–¹å‘è¿›è¡Œå—åŠ›åˆ†æã€‚ ç”±äºæ­¤æ—¶æ‰€å¾—çš„æ–¹ç¨‹æè¿°çš„æ˜¯éçº¿æ€§ç³»ç»Ÿï¼Œæˆ‘ä»¬å°†å…¶çº¿æ€§åŒ–ä»¥ä¾¿è®¾è®¡æ§åˆ¶ç³»ç»Ÿï¼š å¾—åˆ°çº¿æ€§åŒ–å¾®åˆ†æ–¹ç¨‹ï¼š ä¼ é€’å‡½æ•°æè¿° è®¾è¾“å…¥ä¸ºï¼Œè¾“å‡ºå°è½¦ä½ç§»ï¼Œæ‘†é”¤åç§»é‡ã€‚ ç»è¿‡Laplace Transformå¾—åˆ°ï¼š ç”±äºä¼ é€’å‡½æ•°åªèƒ½ç”¨äºæè¿°SISOç³»ç»Ÿï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶æ‹†åˆ†ä¸ºæè¿° ä¸ çš„ä¸¤ä¸ªå¼å­ã€‚ å¾—åˆ°è§’åº¦ç›¸å…³çš„ä¼ é€’å‡½æ•°ï¼š åŒç†å¯æ¨å‡ºä½ç§»ç›¸å…³çš„ä¼ é€’å‡½æ•°ï¼š "},{"title":"ã€0ã€‘çŠ¶æ€ç©ºé—´æ–¹ç¨‹åŸºæœ¬æ¦‚å¿µ","date":"2023-03-28T01:49:50.000Z","url":"/modern-control/state-space-model.html","tags":[["matlab","/tags/matlab/"],["åˆ¶å¾¡å·¥å­¦","/tags/%E5%88%B6%E5%BE%A1%E5%B7%A5%E5%AD%A6/"]],"categories":[["modern-control","/categories/modern-control/"]],"content":"æœ¬èŠ‚ä¸»è¦ä»‹ç»çŠ¶æ€ç©ºé—´æ–¹ç¨‹ä¸­çš„åŸºæœ¬æ¦‚å¿µä»¥ä¾¿å¼•å…¥åç»­å†…å®¹ã€‚ Introduction The modern trend in engineering systems is toward greater complexity, due mainly to the requirements of complex tasks and good accuracy. Complex systems may have multiple inputs and multiple outputs and may be time varying. Because of the necessity of meeting increasingly stringent requirements on the performance of control systems, the increase in system complexity, and easy access to large scale computers, modern control theory, which is a new approach to the analysis and design of complex control systems, has been developed since around 1960. This new approach is based on the concept of state. The concept of state by itself is not new, since it has been in existence for a long time in the field of classical dynamics and other fields. (Ogata, 2010)1 Basic concepts æœ¬èŠ‚é€šè¿‡æ¨å¯¼RCç”µè·¯çš„çŠ¶æ€ç©ºé—´æ–¹ç¨‹å»ºç«‹ç›¸å…³æ¦‚å¿µã€‚ Example of an RLC circuit Input: Output: ç³»ç»Ÿçš„å¾®åˆ†æ–¹ç¨‹è¡¨è¾¾ï¼š åœ¨å¦‚æ­¤çš„ç³»ç»Ÿä¸­ï¼Œæˆ‘ä»¬å®šä¹‰å¦‚ä¸‹å˜é‡ï¼š çŠ¶æ€(state)ï¼šå¯ç”¨äºæè¿°ç³»ç»Ÿè¡Œä¸ºçš„å˜é‡ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬é€‰å–ï¼Œå…¶ä¸­ ï¼Œï¼Œç§°ä¸ºçŠ¶æ€å˜é‡(state variables)ã€‚è€Œå¯¹äºç©ºé—´ s.t. ï¼Œ æˆ‘ä»¬ç§°å…¶ä¸ºçŠ¶æ€ç©ºé—´(state space)ã€‚ ps. çŠ¶æ€å˜é‡å¯ä»¥ä¸æ˜¯å¯æµ‹é‡çš„ç‰©ç†é‡ï¼Œæ–¹ä¾¿ä½¿ç”¨å³å¯ çŠ¶æ€ç©ºé—´æ–¹ç¨‹(state space equations)ï¼šæ˜¯ç”¨äºå»ºç«‹è¾“å…¥ä¸è¾“å‡ºä¹‹é—´å…³ç³»çš„æ–¹ç¨‹ã€‚ â€‹ çŠ¶æ€ç©ºé—´æ–¹ç¨‹çš„ä¸€èˆ¬å½¢å¼ä¸ºï¼š ï¼ˆçŠ¶æ€æ–¹ç¨‹ï¼‰ï¼ˆè¾“å‡ºæ–¹ç¨‹ï¼‰ Modeling åœ¨æœ¬ç³»åˆ—ä¸­ï¼Œæˆ‘ä»¬ä¼šé‡‡ç”¨MATLAB Simulinkè¿›è¡Œå»ºæ¨¡ã€‚ ä»¥ä¸ŠRLCç”µè·¯å»ºæ¨¡å¦‚ä¸‹ï¼š Simulinkå»ºæ¨¡ç¤ºä¾‹ References Ogata, K. (2010). Modern control engineering (Vol. 5). Upper Saddle River, NJ: Prentice hall.â†© "},{"title":"lec01","date":"2022-12-25T11:49:53.000Z","url":"/Artillery/lec01.html","tags":[["Artillery","/tags/Artillery/"],["Robotics","/tags/Robotics/"]],"categories":[["Artillery","/categories/Artillery/"]],"content":"ddd Content å¸¸ç”¨åæ ‡ç³»åŠå…¶å˜æ¢ è‹åˆ¶åæ ‡ç³»&amp;è‹±åˆ¶åæ ‡ç³» åæ ‡ç³»å˜æ¢ ddd è‹åˆ¶åæ ‡ç³»&amp;è‹±åˆ¶åæ ‡ç³» è‹å¼åæ ‡ç³» è‹å¼åæ ‡ç³»ä¸»è¦æœ‰åœ°é¢åæ ‡ç³»ã€å¼¹ï¼ˆæœºï¼‰ä½“åæ ‡ç³»ã€å¼¹é“åæ ‡ç³»ä¸é€Ÿåº¦åæ ‡ç³»ã€‚ åŸç‚¹ï¼šé€šå¸¸ä¸ºå‘å°„ç‚¹ï¼ˆå‘å°„ç¬æ—¶é£è¡Œå™¨çš„è´¨å¿ƒï¼‰ è½´ï¼šé€šå¸¸ä¸ºåŸç‚¹ä¸ç›®æ ‡ä¹‹é—´çš„åœ°çƒå¤§åœ†åˆ‡çº¿ï¼ŒæŒ‡å‘ç›®æ ‡ä¸ºæ­£ã€‚ è½´ï¼šå‚ç›´äº è½´ï¼Œå‘ä¸Šä¸ºæ­£ã€‚ è½´ï¼šå‚ç›´ å¹³é¢ï¼ŒæŒ‰å³æ‰‹åæ ‡ç³»ç¡®å®šæ­£æ–¹å‘ ç‰¹ç‚¹ï¼šå›ºè¿äºåœ°çƒè¡¨é¢ï¼Œéšåœ°çƒä¸€èµ·è½¬åŠ¨ã€‚ è¿‘ä¼¼ï¼šç ”ç©¶è¿‘ç¨‹é£è¡ŒåŠ›å­¦é—®é¢˜æ—¶ï¼Œå¯å¿½ç•¥åœ°çƒçš„è‡ªè½¬å’Œå…¬è½¬ï¼Œå°†åœ°çƒè¡¨é¢çœ‹ä½œå¹³é¢ï¼Œè®¤ä¸ºé‡åŠ›ä¸è½´å¹³è¡Œï¼Œåœ°é¢åæ ‡ç³»å¯çœ‹ä½œæƒ¯æ€§åæ ‡ç³»ã€‚ åŸç‚¹ ï¼šå–åœ¨é£è¡Œå™¨çš„è´¨å¿ƒä¸Šã€‚ è½´ï¼šä¸é£è¡Œå™¨çš„çºµè½´é‡åˆ,æŒ‡å‘é£è¡Œå™¨çš„å¤´éƒ¨ä¸ºæ­£ã€‚ è½´ï¼šï¼ˆç«‹è½´ï¼‰ä½äºé£è¡Œå™¨çš„çºµå‘å¯¹ç§°é¢å†…ï¼Œå‚ç›´äºOx1è½´ï¼Œå‘ä¸Šä¸ºæ­£ã€‚ è½´ï¼šå‚ç›´äº å¹³é¢ï¼ŒæŒ‰å³æ‰‹åæ ‡ç³»ç¡®å®šæ­£æ–¹å‘ã€‚ ä¸å¼¹ä½“å›ºè¿ï¼Œç›¸å¯¹äºå¼¹ä½“ä¸åŠ¨ï¼Œæ˜¯åŠ¨åæ ‡ã€‚ åŸç‚¹Oï¼šå–åœ¨é£è¡Œå™¨çš„è´¨å¿ƒä¸Šã€‚ è½´ï¼šä¸é£è¡Œå™¨çš„é€Ÿåº¦çŸ¢é‡Vé‡åˆã€‚ è½´ï¼šä½äºåŒ…å«é€Ÿåº¦çŸ¢é‡Vçš„é“…å‚é¢å†…ï¼Œå‚ç›´äºOx2è½´ï¼Œå‘ä¸Šä¸ºæ­£ã€‚ è½´ï¼šå‚ç›´äºå¹³é¢ï¼ŒæŒ‰å³æ‰‹åæ ‡ç³»ç¡®å®šæ­£æ–¹å‘ã€‚ ç‰¹ç‚¹ï¼šä¸é£è¡Œå™¨çš„é€Ÿåº¦çŸ¢é‡å›ºè¿ï¼Œæ˜¯åŠ¨åæ ‡ç³»ã€‚ ç”¨é€”ï¼šå°†é£è¡Œå™¨è´¨å¿ƒç§»åŠ¨çš„åŠ¨åŠ›å­¦æ–¹ç¨‹æŠ•å½±åˆ°è¯¥åæ ‡ç³»ä¸Šï¼Œå½¢å¼ç®€å•ï¼Œå«ä¹‰æ¸…æ™°ã€‚ åŸç‚¹ ï¼šå–åœ¨é£è¡Œå™¨çš„è´¨å¿ƒä¸Šã€‚ è½´ï¼šä¸é£è¡Œå™¨çš„é€Ÿåº¦çŸ¢é‡Vé‡åˆã€‚ è½´ï¼šä½äºé£è¡Œå™¨çºµå‘å¯¹ç§°é¢å†…ï¼Œå‚ç›´äº$x_3è½´ï¼Œå‘ä¸Šä¸ºæ­£ã€‚ è½´ï¼šå‚ç›´äº å¹³é¢ï¼ŒæŒ‰å³æ‰‹åæ ‡ç³»ç¡®å®šæ­£æ–¹å‘ã€‚ ç‰¹ç‚¹ï¼šä¸é£è¡Œå™¨é€Ÿåº¦çŸ¢é‡å›ºè¿ï¼Œæ˜¯åŠ¨åæ ‡ç³»ã€‚ ç”¨é€”ï¼šç”¨äºç¡®å®šé£è¡Œå™¨ç›¸å¯¹äºæ°”æµçš„è§’åº¦ï¼›ç©ºæ°”åŠ¨åŠ›æ²¿è¯¥åæ ‡ç³»ä¸‰è½´çš„æŠ•å½±åˆ†åˆ«å®šä¹‰ä¸ºé˜»åŠ›ã€å‡åŠ›å’Œä¾§å‘åŠ›ã€‚ è‹±åˆ¶åæ ‡ç³» å¸¸ç”¨åæ ‡ç³»ä¹‹é—´çš„è”ç³» Remainderï¼šæ­¤å¤„é‡‡ç”¨è‹åˆ¶åæ ‡ç³»å®šä¹‰ã€‚ åœ°é¢&amp;å¼¹ä½“åæ ‡ç³» ä¿¯ä»°è§’ Pitch ()ï¼šé£è¡Œå™¨çºµè½´ï¼ˆï¼‰ä¸æ°´å¹³é¢ï¼ˆï¼‰ä¹‹é—´çš„å¤¹è§’ã€‚é£è¡Œå™¨çºµè½´æŒ‡å‘æ°´å¹³é¢ä¸Šæ–¹åˆ™ä¸ºæ­£ï¼Œåä¹‹ä¸ºè´Ÿã€‚ åèˆªè§’ Yaw ()ï¼šé£è¡Œå™¨çºµè½´åœ¨æ°´å¹³é¢çš„æŠ•å½±ä¸åœ°é¢åæ ‡ç³»è½´ä¹‹é—´çš„å¤¹è§’ã€‚æ²¿è½´ä¿¯è§†ï¼Œè‹¥ç”±è½´é€†æ—¶é’ˆæ—‹è½¬è€Œæˆåˆ™ä¸ºæ­£ï¼Œåä¹‹ä¸ºè´Ÿã€‚ å€¾æ–œè§’ Roll ()ï¼šå¼¹ä½“åæ ‡ç³»çš„è½´ä¸åŒ…å«é£è¡Œå™¨çºµè½´çš„é“…å‚é¢ä¹‹é—´çš„å¤¹è§’ã€‚ç”±é£è¡Œå™¨å°¾éƒ¨é¡ºçºµè½´å‰è§†ï¼Œè‹¥è½´ä½äºé“…å‚é¢å³ä¾§ï¼Œåˆ™ä¸ºæ­£ã€‚ åœ°é¢&amp;å¼¹é“åæ ‡ç³» å¼¹é“å€¾è§’ ()ï¼šé£è¡Œå™¨é€Ÿåº¦çŸ¢é‡ä¸æ°´å¹³é¢ä¹‹é—´çš„å¤¹è§’ã€‚é€Ÿåº¦çŸ¢é‡æŒ‡å‘æ°´å¹³é¢ä¸Šæ–¹ï¼Œä¸ºæ­£ï¼Œåä¹‹ä¸ºè´Ÿã€‚ å¼¹é“åè§’ ()ï¼šé£è¡Œå™¨é€Ÿåº¦çŸ¢é‡åœ¨æ°´å¹³é¢çš„æŠ•å½±ä¸åœ°é¢åæ ‡ç³»è½´ä¹‹é—´çš„å¤¹è§’ã€‚æ²¿è½´ä¿¯è§†ï¼Œè‹¥ç”±è½´é€†æ—¶é’ˆæ—‹è½¬è€Œæˆåˆ™ä¸ºæ­£ï¼Œåä¹‹ä¸ºè´Ÿã€‚ é€Ÿåº¦&amp;å¼¹ä½“åæ ‡ç³»ï¼š æ”»è§’ ()ï¼šé£è¡Œå™¨çš„é€Ÿåº¦çŸ¢é‡åœ¨å¼¹ä½“çºµå‘å¯¹ç§°é¢çš„æŠ•å½±ä¸Ox1è½´ä¹‹é—´çš„å¤¹è§’ã€‚è‹¥Ox1è½´ä½äºé€Ÿåº¦æŠ•å½±çº¿çš„ä¸Šæ–¹ï¼Œåˆ™ä¸ºæ­£ï¼Œåä¹‹ä¸ºè´Ÿã€‚ ä¾§æ»‘è§’ ()ï¼šé£è¡Œå™¨é€Ÿåº¦çŸ¢é‡ä¸çºµå‘å¯¹ç§°é¢ä¹‹é—´çš„å¤¹è§’ã€‚æ²¿é£è¡Œæ–¹å‘è§‚å¯Ÿï¼Œè‹¥æ¥æµä»å³ä¾§æµå‘é£è¡Œå™¨ï¼Œåˆ™ä¸ºæ­£ï¼Œåä¹‹ä¸ºè´Ÿã€‚ åæ ‡ç³»å˜æ¢ ä¸»è¦æ¶‰åŠåˆšä½“è¿åŠ¨ç›¸å…³å†…å®¹ï¼Œé€šè¿‡ æ—‹è½¬çŸ©é˜µã€æŠ•å½±ã€æ¬§æ‹‰è§’ã€å››å…ƒæ•°æè¿°ã€‚ æ—‹è½¬çŸ©é˜µ æŠ•å½± æ¬§æ‹‰è§’ å››å…ƒæ•° Create a quaternion array - MATLAB (mathworks.com)"},{"title":"ã€ç¬”è®°ã€‘é¡¹ç›®ç®¡ç†çš„é€»è¾‘","date":"2022-08-22T00:52:57.000Z","url":"/Project-Management/pro-mgt-lecs.html","tags":[["é¡¹ç›®ç®¡ç†","/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"]],"categories":[["Project-Management","/categories/Project-Management/"]],"content":"æœ¬ç¬”è®°ä¸»è¦è®°å½•æ¸…åå¤§å­¦ç®¡ç†å­¦ç³»åˆ—è®²åº§ç›¸å…³ç¬”è®°ã€‚ ä»€ä¹ˆæ˜¯é¡¹ç›® é¡¹ç›®ä¸è¿è¥ï¼šå›¢é˜Ÿçš„ä¸¤å¤§ä»»åŠ¡ è¿è¥(Operation)ï¼šæŒç»­æ€§ã€é‡å¤æ€§çš„å·¥ä½œï¼Œå¦‚æŠ¥ç¨ã€æŠ¥é”€ã€è®°è´¦ç­‰ é¡¹ç›®(Project)ï¼šé˜¶æ®µæ€§ï¼Œä¸€æ¬¡æ€§çš„å·¥ä½œ é¡¹ç›®æ˜¯ä¸ºåˆ›é€ ç‹¬ç‰¹çš„äº§å“ã€æœåŠ¡æˆ–æˆæœè¿›è¡Œçš„ä¸´æ—¶æ€§å·¥ä½œ â€”â€”PMBOK 6th é¡¹ç›®çš„ç‰¹ç‚¹ ç»„ç»‡é¡¹ç›®ç®¡ç† é¡¹ç›®ç”Ÿå‘½å‘¨æœŸä¸åº”ç”¨ é¡¹ç›®ç”Ÿå‘½å‘¨æœŸä¸»è¦æœ‰ä»¥ä¸‹å‡ ç§ï¼š é¢„æµ‹å‹ è¿­ä»£å‹ å¢é‡å‹ æ•æ·å‹ é¢„æµ‹å‹ åœ¨åšé¡¹ç›®å‰å·²å¯¹é¡¹ç›®ç»“æœå¿ƒä¸­æœ‰æ•° ç»“æœæ˜ç¡®ï¼Œå¼€å‘è¿‡ç¨‹æˆç†Ÿ Example ç»å…¸ç€‘å¸ƒå¼€å‘æ¨¡å‹ æ¯ä¸€æ­¥éœ€è¦å¾ˆå®Œå–„ï¼Œå¾ˆåˆ°ä½ éœ€æ±‚åˆ†æé˜¶æ®µéšä¾¿æéœ€æ±‚ï¼Œä½†å¼€å§‹æ–¹æ¡ˆè®¾è®¡åä¸èƒ½å†åŠ¨ï¼ˆé¡¹ç›®è¿›è¡Œæ–¹å‘ä¸å¯é€†ï¼‰ è¿­ä»£å‹ä¸å¢é‡å‹ è¿­ä»£å‹ï¼š é¡¹ç›®ä¸ºä¸€æ•´ä½“ï¼Œé€ç‰ˆæœ¬è¿­ä»£å‡çº§ å¢é‡å‹ï¼š æ•´ä¸ªé¡¹ç›®åˆ†ä¸ºå¤šä¸ªéƒ¨åˆ†ï¼Œé€ä¸ªäº¤ä»˜ï¼Œæ¯ä¸ªäº¤ä»˜éƒ½æ˜¯å®ŒæˆçŠ¶æ€ å®¢æˆ·å¯æå‰äº†è§£å·¥ä½œæˆæœ é€‚åº”æ€§å¼€å‘ï¼ˆæ•æ·å¼€å‘ï¼‰ Product Backlog: å®¢æˆ·éœ€æ±‚æ±  Sprint: å¼€å‘å‘¨æœŸ æœ‰èŠ‚å¥åœ°ï¼ŒæŒç»­æ€§åœ°è¿›è¡Œé€‚åº”æ€§å¼€å‘ã€‚ ç»¼åˆå¯¹æ¯” ç®¡æ§é¡¹ç›®è¿›åº¦ éœ€æ±‚ä¸æ–­å˜æ›´ï¼Œæ—¶é—´ã€ç‰©è´¨æˆæœ¬ä¸è¶³ï¼šå…ˆä¸Šçº¿ï¼Œåè¿­ä»£ï¼Ÿ\\(\\implies\\) è¿ç»´ä¸ä¾¿ åº”å½“ç¡®å®šåˆç†çš„é¡¹ç›®é˜¶æ®µåˆ’åˆ† é¡¹ç›®çš„é˜¶æ®µåˆ’åˆ† Example 1. å·¥ç¨‹å»ºè®¾ æŒ‰ç…§ä¸“ä¸šæ¯ä¸ªé˜¶æ®µè®¾ç½®å…³å£ï¼ŒåŠæ—¶éªŒæ”¶ï¼Œæ»¡è¶³æ¡ä»¶æ‰å¯è¿›å…¥ä¸‹ä¸€é˜¶æ®µ Example 2. äº§å“è®¾è®¡ ä¸»è¦æµç¨‹ï¼š éœ€æ±‚åˆ†æ â†’ åŸå‹è®¾è®¡ â†’ äº§å“å¼€å‘ â†’ éªŒæ”¶äº¤ä»˜ æ§åˆ¶é¡¹ç›®è´¨é‡ï¼›å‘ç°è„±ç¦»åˆè¡·/éš¾ä»¥ä¿®æ­£æ—¶åŠæ—¶æ­¢æŸ ä¸»è¦çœ‹æ˜¯å¦å®ç°é¡¹ç›®æ—¢å®šç›®æ ‡ã€‚ é¡¹ç›®çš„åˆ†å·¥ é¢å‘é¡¹ç›®çš„ç®¡ç†æ¨¡å¼ ä»¥çŸ©é˜µå½¢å¼ä¸ºç‰¹å¾ï¼š æ—¢æœ‰æŒ‰èŒèƒ½åˆ’åˆ†çš„ä¸“ä¸šéƒ¨é—¨ï¼Œä¹Ÿæœ‰ä»ä¸“ä¸šéƒ¨é—¨æŠ½è°ƒå½¢æˆçš„é¡¹ç›®å›¢é˜Ÿ ç«–å‘åˆ’åˆ†æ˜¯ä¸“ä¸šï¼ŒèŒèƒ½éƒ¨é—¨ï¼›æ¨ªå‘åˆ’åˆ†æ˜¯é¡¹ç›®å›¢é˜Ÿ é¡¹ç›®çš„ç›¸å…³æ–¹ å‡¸æ˜¾æ¨¡å‹ (Salience Model) (è“è‰²ä¸ºæ‰€å…·å¤‡ç‰¹å¾) å–å¾—é¡¹ç›®ç›¸å…³æ–¹å…±è¯† References ã€å…¬å¼€è¯¾ã€‘æ¸…åå¤§å­¦ï¼šé¡¹ç›®ç®¡ç†çš„é€»è¾‘ï¼ˆå…¨6è®²ï¼‰"},{"title":"ç”µè·¯å…ƒä»¶çš„å»ºæ¨¡","date":"2022-08-17T00:00:00.000Z","url":"/%E7%94%B5%E8%B7%AF%E5%88%86%E6%9E%90/Modeling-electric-components.html","tags":[["circuit-analysis","/tags/circuit-analysis/"]],"categories":[["ç”µè·¯åˆ†æ","/categories/%E7%94%B5%E8%B7%AF%E5%88%86%E6%9E%90/"]],"content":"æ—¢ç„¶è‡ªæ§é‚£ç¯‡æ–‡ç« ç”¨åˆ°äº†ç‚¹ é‚£å°±æ•´ä¸Šæ¥( â€¢Ì€ Ï‰ â€¢Ì )âœ§ ## ç”µè·¯å…ƒä»¶çš„å»ºæ¨¡ ç”µé˜» çº¿æ€§ç”µé˜» å¯¹äºçº¿æ€§å®šå¸¸ç”µé˜»ï¼Œï¼Œçº¿æ€§æ—¶å˜åˆ™éã€‚ éçº¿æ€§ç”µé˜» éçº¿æ€§ç”µé˜»å…ƒä»¶çš„é˜»å€¼æœ‰ä¸¤ç§è¡¨ç¤ºæ–¹æ³•ï¼šé™æ€ç”µé˜»(æ€»&gt;0)ï¼ŒåŠ¨æ€ç”µé˜» ç”µå‹/ç”µæµæº ç”µå®¹ çº¦æŸæ–¹ç¨‹ ç”µå®¹çš„ç”µå‹ä¸ä¼šè·³å˜ ç”µæ„Ÿ ç”µæ„Ÿçš„ç”µæµä¸ä¼šè·³å˜"},{"title":"(01)æ•°æ®åˆ†æä¸å»ºæ¨¡","date":"2022-07-08T00:05:49.000Z","url":"/financial-analysis/analyzing-and-modeling.html","tags":[["finance","/tags/finance/"]],"categories":[["financial-analysis","/categories/financial-analysis/"]],"content":"ä½¿ç”¨datasetï¼šä¸Šè¯ 2008.1.2~2022.7.5 æ¯æ—¥æ”¶ç›˜æŒ‡æ•°ï¼Œè¯¦è§github repo data/indx.csv è®©ç›´æ–¹å›¾â€œè¿ç»­â€èµ·æ¥ï¼šç›´æ–¹å›¾ä¸æ ¸å¯†åº¦ä¼°è®¡ ç›´æ–¹å›¾æ˜¯å¯†åº¦çš„ä¸€ä¸ªç›¸å½“ç²—ç³™çš„ä¼°è®¡é‡ï¼Œå®ƒçš„å¤–è§‚å¯¹å•å…ƒæ ¼çš„æ•°ç›®å’Œä½ç½®éƒ½æ˜¯æ•æ„Ÿçš„ï¼Œx,yè½´çš„å˜åŠ¨ä¼šæ˜¾è‘—å½±å“å…¶è§‚æ„Ÿï¼ˆåƒä¸ªæ¸£ç”·, åšå‡ºç‚¹å°å°çš„æ”¹å˜å°±æ¬ºéª—äº†ä½ çš„æ„Ÿæ€§ï¼‰ã€‚å› æ­¤å¼•å…¥æ ¸å¯†åº¦ä¼°è®¡é‡è®©å®ƒæ›´åƒä¸€ä¸ªæ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œæœ¬è´¨ä¸Šæ˜¯åœ¨ä¸€ä¸ªæ•°æ®ç‚¹ä¸Šç»™å‰åçš„æ•°æ®ä»¥ä¸åŒæƒé‡ï¼Œå½¢æˆç›¸å¯¹å¹³æ»‘çš„æ›²çº¿ï¼ˆæ„Ÿæ€§ä¸Šå¯è®¤ä¸ºä¸å·ç§¯ç•¥æœ‰ç›¸ä¼¼ï¼‰ã€‚åŸºäº dataset çš„æ ¸å¯†åº¦ä¼°è®¡é‡å¯ä»¥å†™ä½œï¼š å…¶ä¸­Kä¸€èˆ¬æ˜¯æ ‡å‡†æ­£æ€å¯†åº¦å‡½æ•°å³å…¶ä¸­ï¼Œbè¢«ç§°ä¸ºå¸¦å®½ï¼Œå†³å®šäº†ä¼°è®¡é‡çš„åˆ†è¾¨ç‡ã€‚ æ ¸å¯†åº¦ä¼°è®¡ä½œå›¾è¿˜ç®—ç®€å•ï¼Œå¯ä½¿ç”¨sklearnè‡ªå¸¦å‡½æ•°KernelDensity()ï¼š é™¤æ­¤ä¹‹å¤–ï¼Œæ­¤ æ³•æœ¯ å‡½æ•°è¿˜æœ‰å‰åæ‘‡ï¼š fit(X[, y, sample_weight]) Fit the Kernel Density model on the data. get_params([deep]) Get parameters for this estimator. sample([n_samples, random_state]) Generate random samples from the model. score(X[, y]) Compute the total log-likelihood under the model. score_samples(X) Compute the log-likelihood of each sample under the model. set_params(**params) Set the parameters of this estimator. bçš„å½±å“ï¼šä¸‹å›¾æ˜¯båœ¨ä¸åŒå€¼ä¸‹æ‰€å¾—ç»“æœï¼Œå¯è§bçš„å€¼ä¸æ‹Ÿåˆçš„æ•æ„Ÿåº¦æ˜¯æ­£ç›¸å…³çš„ï¼Œè¿‡å¤§çš„bä¼šé€ æˆè¿‡æ‹Ÿåˆï¼Œè€Œè¿‡å°çš„bä¼šé€ æˆæ¬ æ‹Ÿåˆ å‡‘æˆæ­£æ€åˆ†å¸ƒçš„nç§æ–¹æ³•"},{"title":"ã€ç›®å½•ã€‘Sablinçš„é‡‘èç©å…·ç®±","date":"2022-05-02T19:23:14.000Z","url":"/Finance/finance-toybox.html","tags":[["python","/tags/python/"],["finance","/tags/finance/"]],"categories":[["Finance","/categories/Finance/"]],"content":" æŠ•èµ„æ˜¯ä¸€ç§æ¯”è¾ƒèŠ±é’±çš„ä¸ªäººçˆ±å¥½ã€‚ --Anastasia. Sablina (ğŸ¤”) ç®€ä»‹ï¼š æœ¬ç³»åˆ—æºè‡ªECEåºŸæŸ´Anastasia-Sablinaï¼Œç»å¤§éƒ¨åˆ†å†…å®¹åªèƒ½ä¿è¯è·‘èµ·æ¥[æ¯•ç«Ÿç»å¤§å¤šæ•°åŠŸèƒ½éƒ½æ˜¯è°ƒç”¨åˆ«äººçš„åº“] ( Â´Ï‰` ) . å®é™…ä¸Šæœ¬ç³»åˆ—ä¼šæ›´æ¥è¿‘æŠ€æœ¯åˆ†æ(æŒ‡ä¸èƒ½å­¦å¤§åŸºé‡‘å¹¿æ’’ç½‘) æœ¬ç³»åˆ—ä»£ç ä¸è·‘ç€ç©çš„æ•°æ®é›†å­˜äºgithub repoï¼Œå‚è€ƒä¹¦ç›®å­˜äºåŒä¸€ä»“åº“çš„reference branch. â€‹ åœ¨æœ¬ç³»åˆ—ä¸­æœ‰æ¦‚ç‡ä½¿ç”¨çš„åº“æœ‰ï¼šnumpy, pandas, matplotlib, Scikit-Learn, skorch, PyTorch, TA-Lib (é“¾æ¥ä¸ºå®˜æ–¹æ–‡æ¡£) â€‹ éšç¼˜æ›´ï¼Œå’±çœ‹åˆ°å“ªå†™åˆ°å“ªï¼Œåœ¨è¯„è®ºåŒºé‡Œéª‚è½»ç‚¹ ğŸ™ğŸ¼ åŸºç¡€è®¾æ–½ç¯‡ï¼š é†’é†’ï¼Œä½ äºçƒ‚äº†äº†ï¼šä½¿ç”¨é£ä¹¦æœºå™¨äººé€šçŸ¥ç›¯ç›˜æƒ…å†µ è¢«æ•°æ®æ·¹æ²¡ï¼Œä¸çŸ¥æ‰€æªï¼šæ­å»ºä¸€ä¸ª(æš‚æ—¶)å¤Ÿç”¨çš„æ•°æ®åº“ æ¥å—ç­–ç•¥ï¼ˆå’Œè‡ªå·±ï¼‰å°±æ˜¯åºŸç‰©çš„äº‹å®ï¼šåšä¸ªç”¨å†å²æ•°æ®æ¨¡æ‹Ÿäº¤æ˜“çš„æ¥å£ é‡‘èçŸ¥è¯†ç¯‡ï¼š å³ä½¿æ²¡æœ‰æ”¶ç›Šï¼Œä¸å¦¨ä¹Ÿæ¥çœ‹çœ‹ä»€ä¹ˆæ˜¯æ”¶ç›Š å­¦å­¦å¸¸ç”¨çš„æŠ€æœ¯åˆ†ææŒ‡æ ‡ï¼Œä»¥ä¾¿æ—¥åäºå¾—æ›´æ˜ç™½ (æ¯«æ— å®é™…æ„ä¹‰çš„)å®è·µç¯‡ ä¸çŸ¥å¤©å‘½ï¼Œä½†æ˜¯å¯ä»¥è¯†æ—¶åŠ¡ï¼šé“æ°ç†è®ºçš„ç¨‹åºå®è·µ å¬è¯ï¼Œè®©æˆ‘çœ‹çœ‹ï¼šé€šè¿‡å›å½’åˆ†æè¿›è¡Œå…¬å¸è¯„çº§ RICEQUANTï¼ˆç›®å‰ä½¿ç”¨ï¼Œä½†å­¦ç”Ÿlicenseè¿‡æœŸå°±å¯„äº†ï¼‰ è¯åˆ¸å® Tushare pytdxï¼ˆéƒ¨åˆ†æ•°æ®æœ‰æ•°é‡çº§é—®é¢˜ï¼‰ References å¯¹ä¸ä½æˆ‘çš„æ•™æˆä»¬äº† ä½†æˆ‘æ˜¯çœŸä¸æƒ³å†å†™APA citationäº†å‘œå‘œå‘œï¼ˆï¼äººï¼œï¼›ï¼‰ Python for Data Analysis: DATA WRANGLING WITH PANDAS, NUMPY, AND IPYTHON Successful Arithmetic Trading é‡‘èç»Ÿè®¡ä¸æ•°æ®åˆ†æ, David Ruppert æ‰“å¼€é‡åŒ–æŠ•èµ„çš„é»‘ç®±(åŸä¹¦ç¬¬äºŒç‰ˆ), Rishi K. Narang ç»å…¸æŠ€æœ¯åˆ†æ(åŸä¹¦ç¬¬ä¸‰ç‰ˆ), Charles. D. Kirkpatrick. â…¡"}]